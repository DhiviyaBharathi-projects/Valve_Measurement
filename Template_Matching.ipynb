{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45035615-84bc-4c2a-88e3-3f91e27c4008",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import json\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "class EnhancedMeasurementSystem:\n",
    "    def __init__(self):\n",
    "        self.quality_threshold = 0.8\n",
    "        self.min_matches = 10\n",
    "        self.measurement_uncertainty = 0.05  # 5% uncertainty\n",
    "        \n",
    "    def enhanced_feature_matching(self, template_gray, new_gray):\n",
    "        \"\"\"Enhanced feature matching with better filtering\"\"\"\n",
    "        # SIFT feature detection\n",
    "        sift = cv2.SIFT_create(nfeatures=500)\n",
    "        kp1, des1 = sift.detectAndCompute(template_gray, None)\n",
    "        kp2, des2 = sift.detectAndCompute(new_gray, None)\n",
    "        \n",
    "        if des1 is None or des2 is None:\n",
    "            raise ValueError(\"Could not detect sufficient features\")\n",
    "        \n",
    "        # FLANN matching\n",
    "        FLANN_INDEX_KDTREE = 1\n",
    "        index_params = dict(algorithm=FLANN_INDEX_KDTREE, trees=5)\n",
    "        search_params = dict(checks=50)\n",
    "        flann = cv2.FlannBasedMatcher(index_params, search_params)\n",
    "        matches = flann.knnMatch(des1, des2, k=2)\n",
    "        \n",
    "        # Enhanced ratio test filtering\n",
    "        good_matches = []\n",
    "        for match_pair in matches:\n",
    "            if len(match_pair) == 2:\n",
    "                m, n = match_pair\n",
    "                if m.distance < 0.7 * n.distance:\n",
    "                    good_matches.append(m)\n",
    "        \n",
    "        # K-nearest neighbors validation\n",
    "        good_matches = self.knn_filter(good_matches, kp1, kp2)\n",
    "        \n",
    "        return good_matches, kp1, kp2\n",
    "    \n",
    "    def knn_filter(self, matches, kp1, kp2, k=5):\n",
    "        \"\"\"K-nearest neighbors filtering for better matches\"\"\"\n",
    "        if len(matches) < k:\n",
    "            return matches\n",
    "            \n",
    "        # Calculate spatial consistency\n",
    "        filtered_matches = []\n",
    "        for i, match in enumerate(matches):\n",
    "            pt1 = kp1[match.queryIdx].pt\n",
    "            pt2 = kp2[match.trainIdx].pt\n",
    "            \n",
    "            # Find k nearest matches\n",
    "            distances = []\n",
    "            for j, other_match in enumerate(matches):\n",
    "                if i != j:\n",
    "                    other_pt1 = kp1[other_match.queryIdx].pt\n",
    "                    other_pt2 = kp2[other_match.trainIdx].pt\n",
    "                    \n",
    "                    dist1 = np.linalg.norm(np.array(pt1) - np.array(other_pt1))\n",
    "                    dist2 = np.linalg.norm(np.array(pt2) - np.array(other_pt2))\n",
    "                    distances.append((j, abs(dist1 - dist2)))\n",
    "            \n",
    "            # Sort by spatial consistency\n",
    "            distances.sort(key=lambda x: x[1])\n",
    "            \n",
    "            # Keep matches with good spatial consistency\n",
    "            if len(distances) >= k-1:\n",
    "                avg_inconsistency = np.mean([d[1] for d in distances[:k-1]])\n",
    "                if avg_inconsistency < 50:  # Threshold for spatial consistency\n",
    "                    filtered_matches.append(match)\n",
    "        \n",
    "        return filtered_matches\n",
    "    \n",
    "    def quality_check(self, homography, matches, kp1, kp2):\n",
    "        \"\"\"Quality check for measurement reliability\"\"\"\n",
    "        if len(matches) < self.min_matches:\n",
    "            return False, f\"Insufficient matches: {len(matches)}\"\n",
    "        \n",
    "        # Check homography condition\n",
    "        det = np.linalg.det(homography[:2, :2])\n",
    "        if abs(det) < 0.1 or abs(det) > 10:\n",
    "            return False, f\"Poor homography condition: {det}\"\n",
    "        \n",
    "        # Check reprojection error\n",
    "        src_pts = np.float32([kp1[m.queryIdx].pt for m in matches]).reshape(-1, 1, 2)\n",
    "        dst_pts = np.float32([kp2[m.trainIdx].pt for m in matches]).reshape(-1, 1, 2)\n",
    "        \n",
    "        projected_pts = cv2.perspectiveTransform(src_pts, homography)\n",
    "        errors = np.linalg.norm(projected_pts - dst_pts, axis=2).flatten()\n",
    "        mean_error = np.mean(errors)\n",
    "        \n",
    "        if mean_error > 5.0:\n",
    "            return False, f\"High reprojection error: {mean_error:.2f}\"\n",
    "        \n",
    "        return True, f\"Quality OK: {len(matches)} matches, error: {mean_error:.2f}\"\n",
    "    \n",
    "    def pixel_to_physical_conversion(self, pixel_length, dx, dy, ref_horizontal, ref_vertical):\n",
    "        \"\"\"Enhanced pixel to physical unit conversion with uncertainty\"\"\"\n",
    "        if ref_horizontal <= 0 or ref_vertical <= 0:\n",
    "            raise ValueError(\"Invalid reference measurements\")\n",
    "        \n",
    "        # Calculate components\n",
    "        horizontal_component = abs(dx) / ref_horizontal\n",
    "        vertical_component = abs(dy) / ref_vertical\n",
    "        \n",
    "        # Physical length\n",
    "        length_cm = np.sqrt(horizontal_component**2 + vertical_component**2)\n",
    "        \n",
    "        # Calculate uncertainty\n",
    "        h_uncertainty = self.measurement_uncertainty * horizontal_component\n",
    "        v_uncertainty = self.measurement_uncertainty * vertical_component\n",
    "        total_uncertainty = np.sqrt(h_uncertainty**2 + v_uncertainty**2)\n",
    "        \n",
    "        return length_cm, total_uncertainty\n",
    "    \n",
    "    def generate_measurement_report(self, measurements, image_path, quality_info):\n",
    "        \"\"\"Generate structured measurement report\"\"\"\n",
    "        timestamp = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "        \n",
    "        report = {\n",
    "            \"metadata\": {\n",
    "                \"timestamp\": timestamp,\n",
    "                \"image_path\": image_path,\n",
    "                \"quality_score\": quality_info,\n",
    "                \"measurement_count\": len(measurements)\n",
    "            },\n",
    "            \"measurements\": [],\n",
    "            \"statistics\": {\n",
    "                \"total_measurements\": len(measurements),\n",
    "                \"avg_length\": 0,\n",
    "                \"min_length\": float('inf'),\n",
    "                \"max_length\": 0\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        lengths = []\n",
    "        for i, measurement in enumerate(measurements):\n",
    "            length = measurement['length_cm']\n",
    "            uncertainty = measurement.get('uncertainty', 0)\n",
    "            lengths.append(length)\n",
    "            \n",
    "            report[\"measurements\"].append({\n",
    "                \"id\": i + 1,\n",
    "                \"label\": measurement['label'],\n",
    "                \"length_cm\": round(length, 3),\n",
    "                \"length_mm\": round(length * 10, 2),\n",
    "                \"length_inches\": round(length / 2.54, 3),\n",
    "                \"uncertainty_cm\": round(uncertainty, 4),\n",
    "                \"confidence\": \"High\" if uncertainty < 0.05 else \"Medium\" if uncertainty < 0.1 else \"Low\",\n",
    "                \"angle_degrees\": measurement['angle_degrees'],\n",
    "                \"coordinates\": {\n",
    "                    \"point1\": measurement['point1'],\n",
    "                    \"point2\": measurement['point2']\n",
    "                }\n",
    "            })\n",
    "        \n",
    "        # Calculate statistics\n",
    "        if lengths:\n",
    "            report[\"statistics\"][\"avg_length\"] = round(np.mean(lengths), 3)\n",
    "            report[\"statistics\"][\"min_length\"] = round(np.min(lengths), 3)\n",
    "            report[\"statistics\"][\"max_length\"] = round(np.max(lengths), 3)\n",
    "            report[\"statistics\"][\"std_deviation\"] = round(np.std(lengths), 3)\n",
    "        \n",
    "        return report\n",
    "    \n",
    "    def enhanced_match_and_measure(self, new_image_path, template_image_path, template_json_path):\n",
    "        \"\"\"Enhanced matching and measurement with all improvements\"\"\"\n",
    "        try:\n",
    "            # Read images\n",
    "            new_img = cv2.imread(new_image_path)\n",
    "            template_img = cv2.imread(template_image_path)\n",
    "            \n",
    "            if new_img is None or template_img is None:\n",
    "                raise ValueError(\"Could not load images\")\n",
    "            \n",
    "            # Convert to grayscale\n",
    "            new_gray = cv2.cvtColor(new_img, cv2.COLOR_BGR2GRAY)\n",
    "            template_gray = cv2.cvtColor(template_img, cv2.COLOR_BGR2GRAY)\n",
    "            \n",
    "            # Load template data\n",
    "            with open(template_json_path, 'r') as f:\n",
    "                template_data = json.load(f)\n",
    "            \n",
    "            # Enhanced feature matching\n",
    "            good_matches, kp1, kp2 = self.enhanced_feature_matching(template_gray, new_gray)\n",
    "            \n",
    "            # Get matched points for homography\n",
    "            src_pts = np.float32([kp1[m.queryIdx].pt for m in good_matches]).reshape(-1, 1, 2)\n",
    "            dst_pts = np.float32([kp2[m.trainIdx].pt for m in good_matches]).reshape(-1, 1, 2)\n",
    "            \n",
    "            # Find homography with RANSAC\n",
    "            homography, mask = cv2.findHomography(\n",
    "                src_pts, dst_pts, \n",
    "                cv2.RANSAC, \n",
    "                ransacReprojThreshold=5.0,\n",
    "                confidence=0.99\n",
    "            )\n",
    "            \n",
    "            if homography is None:\n",
    "                raise ValueError(\"Could not compute homography\")\n",
    "            \n",
    "            # Quality check\n",
    "            quality_ok, quality_info = self.quality_check(homography, good_matches, kp1, kp2)\n",
    "            if not quality_ok:\n",
    "                print(f\"Warning: {quality_info}\")\n",
    "            \n",
    "            # Process measurements\n",
    "            result_img = new_img.copy()\n",
    "            measurements = []\n",
    "            ref_horizontal = template_data['reference']['horizontal']\n",
    "            ref_vertical = template_data['reference']['vertical']\n",
    "            \n",
    "            for measure in template_data['measurements']:\n",
    "                # Transform points\n",
    "                pt1 = np.float32([[measure['point1']['x'], measure['point1']['y']]])\n",
    "                pt2 = np.float32([[measure['point2']['x'], measure['point2']['y']]])\n",
    "                \n",
    "                transformed_pt1 = cv2.perspectiveTransform(pt1.reshape(-1, 1, 2), homography)\n",
    "                transformed_pt2 = cv2.perspectiveTransform(pt2.reshape(-1, 1, 2), homography)\n",
    "                \n",
    "                pt1_new = tuple(map(int, transformed_pt1[0][0]))\n",
    "                pt2_new = tuple(map(int, transformed_pt2[0][0]))\n",
    "                \n",
    "                # Calculate measurements with uncertainty\n",
    "                dx = pt2_new[0] - pt1_new[0]\n",
    "                dy = pt2_new[1] - pt1_new[1]\n",
    "                pixel_length = np.sqrt(dx**2 + dy**2)\n",
    "                \n",
    "                length_cm, uncertainty = self.pixel_to_physical_conversion(\n",
    "                    pixel_length, dx, dy, ref_horizontal, ref_vertical\n",
    "                )\n",
    "                \n",
    "                # Calculate angle\n",
    "                angle = np.degrees(np.arctan2(dy, dx))\n",
    "                if angle < 0:\n",
    "                    angle += 360\n",
    "                \n",
    "                # Store measurement\n",
    "                measurements.append({\n",
    "                    'label': measure['label'],\n",
    "                    'point1': pt1_new,\n",
    "                    'point2': pt2_new,\n",
    "                    'length_cm': length_cm,\n",
    "                    'uncertainty': uncertainty,\n",
    "                    'angle_degrees': angle\n",
    "                })\n",
    "                \n",
    "                # Draw on image\n",
    "                cv2.circle(result_img, pt1_new, 5, (255, 0, 0), -1)\n",
    "                cv2.circle(result_img, pt2_new, 5, (255, 0, 0), -1)\n",
    "                cv2.line(result_img, pt1_new, pt2_new, (0, 255, 0), 2)\n",
    "                \n",
    "                # Add enhanced labels\n",
    "                mid_point = ((pt1_new[0] + pt2_new[0])//2, (pt1_new[1] + pt2_new[1])//2)\n",
    "                cv2.putText(result_img, measure['label'], \n",
    "                           (mid_point[0], mid_point[1]-10), \n",
    "                           cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 0, 0), 2)\n",
    "                cv2.putText(result_img, f'{length_cm:.2f}±{uncertainty:.3f}cm', \n",
    "                           (mid_point[0], mid_point[1]+20),\n",
    "                           cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 2)\n",
    "            \n",
    "            # Generate comprehensive report\n",
    "            report = self.generate_measurement_report(measurements, new_image_path, quality_info)\n",
    "            \n",
    "            # Save results\n",
    "            timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "            cv2.imwrite(f'enhanced_measurement_{timestamp}.png', result_img)\n",
    "            \n",
    "            with open(f'enhanced_report_{timestamp}.json', 'w') as f:\n",
    "                json.dump(report, f, indent=4)\n",
    "            \n",
    "            return result_img, measurements, report\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error in measurement process: {str(e)}\")\n",
    "            return None, None, None\n",
    "\n",
    "# Usage example\n",
    "if __name__ == \"__main__\":\n",
    "    system = EnhancedMeasurementSystem()\n",
    "    # new_image = \n",
    "    # template_image = \n",
    "    # template_json = \n",
    "    \n",
    "    result_img, measurements, report = system.enhanced_match_and_measure(\n",
    "        new_image, template_image, template_json\n",
    "    )\n",
    "    \n",
    "    if report:\n",
    "        print(\"Measurement Report:\")\n",
    "        print(f\"Total measurements: {report['statistics']['total_measurements']}\")\n",
    "        print(f\"Average length: {report['statistics']['avg_length']} cm\")\n",
    "        for measurement in report['measurements']:\n",
    "            print(f\"{measurement['label']}: {measurement['length_cm']} ± {measurement['uncertainty_cm']} cm\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
